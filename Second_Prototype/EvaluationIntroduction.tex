\subsection{Evaluation Plan}
\label{sub:evaluation_plan}

Having incorporated aspects of the first generation prototypes based on our
evaluation of them, we will now evaluate our final design using the same
methods as well as using a cognitive walkthrough and a usability questionnaire.

We will begin the evaluation of our second generation prototype by testing it
against Neilsen's heuristics. The main goal of heuristic evaluations is to
identify any problems associated with the design of user interface by means of
a systematic inspection. We would hope to see a reduction in usability problems
compared to the first generation prototypes.

Next will be an examination of the potential scenarios proposed by each
persona. With a more detailed and robust design, we can examine each scenario
in more depth and again hope to see an improvement in the way this prototype
deals with them. We will then apply an inspection method called a cognitive
walkthrough. This is a more formal approach to imagining people's thoughts and
actions when they use an interface for the first time. This allows us to put
ourselves in the shoes of a user while they aim to carry out a particular task
with a certain goal in mind. We will select one task for each persona that the
design is intended to support and then step through each action in that task.
This method should help us find any obstacles a user may face when using the
application having had no experience with it. We must motivate the actions
based on the user's general knowledge and on feedback provided by the
interface.

There are four questions to consider in a cognitive walkthrough\cite{cogwalk}:
\begin{enumerate}
	\item \textbf{Will the customer realistically be trying to do this action?}

	Does the interface make unrealistic assumptions about the level of
	knowledge or experience that users have?

	\item \textbf{Is the control for the action visible?}

	Highlights issues with context-sensitive menus or controls buried too deep
	within a navigation system and identifies non-standard and unintuitive
	icons/buttons.

	\item \textbf{Is there a strong link between the control and the action?}

	Identifies problems with ambiguous or jargon terms.

	\item \textbf{If the correct  action is performed, will the user see that
		progress is being made?}

	Helps to find problems when feedback is unclear, ambiguous or missing
	entirely.

\end{enumerate}
\bigskip

We must decide if each of these questions is a pass or a fail for every action
within the tasks.

Finally we will construct a questionnaire to test usability.  Usability testing
is a technique which will allow us to evaluate our design by testing it on
members of the public. By doing this it allows us to gain a subject assessment.
This is important as having designed the application ourselves, we as designers
know exactly how it works and can make the error of assuming to understand the
user.

We will take an informal approach with our questionnaire by sitting the user
down with the system and letting them use it as they like. Their feedback will
be recorded on the questionnaire and we will use the system usability scale
test to analyse our results and draw any conclusions.

If time restriction was not an issue, there are other inspection methods we
could have applied.  For example, using the consistency inspection method we
could have asked designers who represent multiple other projects to inspect our
interface to see whether it does things in the same way as their own designs.
However, finding designers who represent multiple projects in our time frame is
not plausible.

The feature inspection lists sequences of features used to accomplish typical
tasks, checks for long sequences, unnatural and complicated steps, and steps
that require extensive knowledge and experience in order to assess a proposed
feature set. This method of evaluation would not be beneficial to us as it is
very similar to the cognitive walkthrough and our application does not require
extensive knowledge or experience.
