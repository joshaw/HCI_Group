\subsection{Evaluation Plan}
\label{sub:evaluation_plan}

Having incorporated aspects of the first generation prototypes based on our
evaluation of them, we will now evaluate our final design using the same
methods as well as using a cognitive walkthrough and a usability questionnaire.

With a more detailed and robust design, we can examine each scenario in more
depth and have an expectation of finding fewer usability problems after our
systematic inspection driven by heuristics.

The cognitive walkthrough is an inspection method which we did not use in the
evaluation of the first generation prototypes. It is a more formal approach to
imagining people's thoughts and actions when they use an interface for the
first time. This allows us to put ourselves in the shoes of a user while they
aim to carry out a particular task with a certain goal in mind. We will select
one task for each persona that the design is intended to support and then step
through each action in that task. This method should help us find any obstacles
a user may face when using the application having had no experience with it. We
must motivate the actions based on the user's general knowledge and on feedback
provided by the interface.

There are four questions to consider in a cognitive walkthrough\cite{cogwalk}:
\begin{enumerate}
	\item \textbf{Will the customer realistically be trying to do this action?}

	Does the interface make unrealistic assumptions about the level of
	knowledge or experience that users have?

	\item \textbf{Is the control for the action visible?}

	Highlights issues with context-sensitive menus or controls buried too deep
	within a navigation system and identifies non-standard and unintuitive
	icons/buttons.

	\item \textbf{Is there a strong link between the control and the action?}

	Identifies problems with ambiguous or jargon terms.

	\item \textbf{If the correct  action is performed, will the user see that
		progress is being made?}

	Helps to find problems when feedback is unclear, ambiguous or missing
	entirely.

\end{enumerate}
\bigskip

We must decide if each of these questions is a pass or a fail for every action
within the tasks.

Finally we will construct a questionnaire to test usability.  Usability testing
is a technique which will allow us to evaluate our design by testing it on
members of the public. By doing this it allows us to gain a subject assessment.
This is important as having designed the application ourselves, we as designers
know exactly how it works and can make the error of assuming to understand the
user.

We will take an informal approach with our questionnaire by sitting the user
down with the system and letting them use it as they like. Their feedback will
be recorded on the questionnaire and we will use the system usability scale
test to analyse our results and draw any conclusions.

If time restriction was not an issue, there are other inspection methods we
could have applied.  For example, using the consistency inspection method we
could have asked designers who represent multiple other projects to inspect our
interface to see whether it does things in the same way as their own designs.
However, finding designers who represent multiple projects in our time frame is
not plausible.

The feature inspection lists sequences of features used to accomplish typical
tasks, checks for long sequences, unnatural and complicated steps, and steps
that require extensive knowledge and experience in order to assess a proposed
feature set. This method of evaluation would not be beneficial to us as it is
very similar to the cognitive walkthrough and our application does not require
extensive knowledge or experience.
